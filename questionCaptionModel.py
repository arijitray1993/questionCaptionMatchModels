'''
Code for Caption-Question Similarity Models for predicting relevance of a question for an image.
@author: Arijit Arren Ray

Virginia Tech Computer Vision Lab, Spring 2016

Please email ray93@vt.edu for questions. 
'''

import sys
import argparse
from datetime import datetime
import numpy as np
import json

import spacy
from spacy.en import English
import spacy.parts_of_speech


from keras.models import Sequential
from keras.layers import Dense,Activation, Dropout
from keras.layers import Merge, LSTM, Dense
from keras.optimizers import *

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score

#----- LOAD DATA  ------

def load_data(args):
	
	if args.cap_type=='qq':
		print "Loading Questions generated by a Pre Trained Captioning Model for Images..."
		with open("imagecaptions_as_ques.json") as filename:
			image_captions=json.load(filename)  # 1500 unique images from Devi's data captioned by caption generator.

	if args.cap_type=='qc':
		print "Loading Captions generated by a Pre-Trained Captioning Model for Images..."
		with open("imagecaptions.json") as filename:
			image_captions=json.load(filename)  # 1500 unique images from Devi's data captioned by caption generator.

	if args.cap_type=='qdq':
		print "Loading Diverse Questions generated by a Pre-Trained Captioning Model for Images..."
		with open("quesascaptiondiverse.json") as filename:
			image_captions=json.load(filename)  # 1500 unique images from Devi's data captioned by caption generator.


	with open("RamScoresNew.json") as filename:
		qi_applicable=json.load(filename)   # 1 Makes Sense, 2 doesnt make sense, a total of 32139 QI pairs

	with open("vocabquestions.json") as filename:
		vocab=json.load(filename)


	#invert vocab for faster indexing of word to number
	invertvocab=dict()
	for key,value in vocab.iteritems():
		invertvocab[value]=int(key)

	return image_captions,qi_applicable, vocab, invertvocab


#----- Build features for question and captions ---------------

def feature_extract_naive(unique_qi_applicable, image_captions, vocab, invertvocab):
	print "Compute Similarity using Bag of Words..."
	#Naive Way
	ques_cap_features=np.zeros((len(unique_qi_applicable),len(vocab)))
	#ques_cap_features=np.zeros((len(unique_qi_applicable),30))
	applicable_labels=[]	
	for index,ques_entry in enumerate(unique_qi_applicable.items()):
		#print ques_entry
		
		if ques_entry[1]['label']!='':		
			question=ques_entry[1]['question']
			words=question.split(' ')
			count=0
			for word in words:
				if word in invertvocab:
					if word.lower()!='is' or word.lower()!='the' or word.lower()!='what' or word.lower()!='that' or word.lower()!='to' or word.lower()!='who' or word.lower()!='why':
						ques_cap_features[index][invertvocab[word]-1]+=1 #index-1 because of 0 indexing in python
						#ques_cap_features[index][count]=invertvocab[word]
						#count+=1
						#print word
		
			image= ques_entry[1]['image'].split('/home/deep/Projects/Datasets/mscoco/mscoco/images/val2014/')[1]

			image_url='applicabledataimages/val2014/'+image
		
			caption=image_captions[image_url]
		
			words=caption.split(' ')
			#count=15
			for word in words:
				if word in invertvocab:
					if word.lower()!='is' or word.lower()!='the' or word.lower()!='what' or word.lower()!='that' or word.lower()!='to' or word.lower()!='who' or word.lower()!='why':
						ques_cap_features[index][invertvocab[word]-1]+=1
						#ques_cap_features[index][count]=invertvocab[word]
						#count+=1
			applicable_labels.append(2-int(ques_entry[1]['label']))
		else:
			applicable_labels.append(0)
	return ques_cap_features,applicable_labels


def feature_extract_word2vec(unique_qi_applicable, image_captions):
	print "Compute Similarity using Averaged Word2Vec..."
	ques_cap_features=[]
	applicable_labels=[]
		
	for index,ques_entry in enumerate(unique_qi_applicable.items()):
		#print ques_entry
		
		if ques_entry[1]['label']!='':		
			question=ques_entry[1]['question']
			words=question.split(' ')
			count=0
			ques_features=[]
			cap_features=[]
			#print "Generating Question_features..."
			for word in words:
				if word in w2v:
					if word.lower()!='is' or word.lower()!='a' or word.lower()!='the' or word.lower()!='what' or word.lower()!='that' or word.lower()!='to' or word.lower()!='who' or word.lower()!='why':
						ques_features.append(w2v[word])
						#ques_cap_features[index][count]=invertvocab[word]
						#count+=1
						#print word
			ques_features=sum(ques_features)/float(len(ques_features))
			image= ques_entry[1]['image'].split('/home/deep/Projects/Datasets/mscoco/mscoco/images/val2014/')[1]

			image_url='applicabledataimages/val2014/'+image
		
			caption=image_captions[image_url]
		
			words=caption.split(' ')
			#count=15
			#print "generating Answer Features..."
			for word in words:
				if word in w2v:
					if word.lower()!='is' or word.lower()!='a' or word.lower()!='the' or word.lower()!='what' or word.lower()!='that' or word.lower()!='to' or word.lower()!='who' or word.lower()!='why':
						cap_features.append(w2v[word])
						#ques_cap_features[index][count]=invertvocab[word]
						#count+=1

			cap_features=sum(cap_features)/float(len(cap_features))

			ques_cap_features.append(np.concatenate((ques_features,cap_features),0))

			applicable_labels.append(2-int(ques_entry[1]['label']))
	
	ques_cap_features=np.asarray(ques_cap_features)
	applicable_labels=np.asarray(applicable_labels)	
	
	return ques_cap_features,applicable_labels


def feature_extract_lstm(unique_qi_applicable, image_captions):
	print "Compute Similarity using an LSTM on Word2Vec..."
	question_features=[]
	caption_features=[]
	applicable_labels=[]
		
	for index,ques_entry in enumerate(unique_qi_applicable.items()):
		#print ques_entry
		
		if ques_entry[1]['label']!='':		
			question=ques_entry[1]['question']
			words=question.split(' ')
			count=0
			ques_features=np.zeros((20,300))
			cap_features=np.zeros((20,300))
			qc=0
			cc=0
			#print "Generating Question_features..."
			for word in words:
				if word in w2v:
					if word.lower()!='is' or word.lower()!='a' or word.lower()!='the' or word.lower()!='what' or word.lower()!='that' or word.lower()!='to' or word.lower()!='who' or word.lower()!='why':
						ques_features[qc]=w2v[word]
						qc+=1
						#ques_cap_features[index][count]=invertvocab[word]
						#count+=1
						#print word
			
			image= ques_entry[1]['image'].split('/home/deep/Projects/Datasets/mscoco/mscoco/images/val2014/')[1]

			image_url='applicabledataimages/val2014/'+image
		
			caption=image_captions[image_url]
		
			words=caption.split(' ')
			#count=15
			for word in words:
				if word in w2v:
					if word.lower()!='is' or word.lower()!='a' or word.lower()!='the' or word.lower()!='what' or word.lower()!='that' or word.lower()!='to' or word.lower()!='who' or word.lower()!='why':
						cap_features[cc]=w2v[word]
						cc+=1
						#ques_cap_features[index][count]=invertvocab[word]
						#count+=1
			ques_features=np.asarray(ques_features)
			cap_features=np.asarray(cap_features)

			question_features.append(ques_features)
			caption_features.append(cap_features)

			applicable_labels.append(2-int(ques_entry[1]['label']))
		
	question_features=np.asarray(question_features)
	caption_features=np.asarray(caption_features)
	applicable_labels=np.asarray(applicable_labels)
	
	return question_features,caption_features, applicable_labels

#-------- Training Module ---------------------------

def train_model(X_train, y_train, loadWeights=None):
	model=Sequential()
	#model.add(Dense(30,input_dim=len(vocab),activation='relu'))
	model.add(Dense(200,input_dim=600,activation='relu'))
	model.add(Dense(150,activation='relu'))
	model.add(Dense(80,activation='relu'))
	model.add(Dense(1,activation='sigmoid'))

	model.compile(loss='binary_crossentropy',optimizer='adadelta')

#	print len(X_train)
#	print len(y_train)

	if loadWeights!=None:
		print "Loading Pretrained Weights..."
		model.load_weights(loadWeights) #600in,200,150,10,1
	else:
		print "Training Model..."
		model.fit(X_train,y_train, nb_epoch=30, show_accuracy=True)
	return model

def train_model_naive(X_train, y_train, vocab, loadWeights=None):
	model=Sequential()
	model.add(Dense(30,input_dim=len(vocab),activation='relu'))
	model.add(Dense(20,activation='relu'))
	model.add(Dense(10,activation='relu'))
	model.add(Dense(1,activation='sigmoid'))

	model.compile(loss='binary_crossentropy',optimizer='adadelta')

#	print len(X_train)
#	print len(y_train)

	if loadWeights!=None: 	
		print "Loading Pretrained Weights..."
		model.load_weights(loadWeights) #600in,200,150,10,1
	else:
		print "Training Model..."
		model.fit(X_train,y_train, nb_epoch=9, show_accuracy=True)
	return model


def test_model(X_test, y_test, model):
	
	pred=model.predict_proba(X_test)
	thresh=0.15
	pred_labels=pred>thresh
	gt_labels=np.asarray(y_test)>0.5
	pred_labels_n=pred<thresh
	gt_labels_n=np.asarray(y_test)<0.5

	return pred_labels,gt_labels,pred_labels_n,gt_labels_n

def train_model_lstm(X_train_ques, X_train_cap, y_train, loadWeights=None):
	data_dim = 300
	timesteps = 20
	nb_classes = 1
	print "Defining Architecture..."
	encoder_a = Sequential()
	encoder_a.add(LSTM(40, input_shape=(timesteps,data_dim)))
	#encoder_a.add(LSTM(40))

	encoder_b = Sequential()
	encoder_b.add(LSTM(40, input_shape=(timesteps,data_dim)))
	#encoder_b.add(LSTM(40))

	decoder = Sequential()
	decoder.add(Merge([encoder_a, encoder_b], mode='concat'))
	decoder.add(Dense(40, activation='relu'))
	decoder.add(Dense(20, activation='relu'))
	decoder.add(Dense(nb_classes, activation='sigmoid'))
	
	decoder.compile(loss='binary_crossentropy', optimizer='rmsprop')
	print "Architecture Defined..."

	X_train_ques=np.asarray(X_train_ques)
	X_train_cap=np.asarray(X_train_cap)
	y_train=np.asarray(y_train)
	
	if loadWeights!=None:
		decoder.load_weights(loadWeights)
	else:
		print "Fitting model..."
		'''
		for epoch in range(1,3):
			for i in range(0,len(X_train_ques)):
				decoder.fit([np.asarray([X_train_ques[i]]), np.asarray([X_train_cap[i]])], np.asarray([y_train[i]]), nb_epoch=1)
		'''
		decoder.fit([X_train_ques,X_train_cap], y_train, nb_epoch=38)
	
	return decoder


def test_model_lstm(X_test_ques, X_test_cap, y_test, model):

	X_test_ques=np.asarray(X_test_ques)
	X_test_cap=np.asarray(X_test_cap)
	y_test=np.asarray(y_test)
	
	pred=model.predict_proba([X_test_ques, X_test_cap])
	thresh=0.15
	pred_labels=pred>thresh
	gt_labels=np.asarray(y_test)>0.5
	pred_labels_n=pred<thresh
	gt_labels_n=np.asarray(y_test)<0.5

	return pred_labels,gt_labels,pred_labels_n,gt_labels_n
	
	
def uniquify_data(qi_applicable):
	tcount=0
	unique_qi_applicable=dict()	
	for entry in qi_applicable.items():
		if entry[1]['label']!='':
			key=entry[1]['image']+'__'+entry[1]['question']
			if key in unique_qi_applicable:
					
				unique_qi_applicable[key]['lcounts'].append(int(entry[1]['label']))
				if len(unique_qi_applicable[key]['lcounts'])>0:
					if len(unique_qi_applicable[key]['lcounts'])==2:
						tcount+=1
						#print tcount
					if np.mean(unique_qi_applicable[key]['lcounts'])>=1.5:
						unique_qi_applicable[key]['label']=2
					else:
						unique_qi_applicable[key]['label']=1
			else:
				unique_qi_applicable[key]=dict()
				unique_qi_applicable[key]['lcounts']=[]
				unique_qi_applicable[key]['lcounts'].append(int(entry[1]['label']))
				unique_qi_applicable[key]['question']=entry[1]['question']
				unique_qi_applicable[key]['image']=entry[1]['image']
				if len(unique_qi_applicable[key]['lcounts'])>0:
					if np.mean(unique_qi_applicable[key]['lcounts'])>=1.5:
						unique_qi_applicable[key]['label']=2
					else:
						unique_qi_applicable[key]['label']=1

	return unique_qi_applicable


#----- MAIN FUNCTION ---------------------

def run_avg_w2v_model(cfg):	
	
	print "Loading Data ..."
	image_captions, qi_applicable, vocab, invertvocab= load_data(args)
	
	#qi_applicable has 32139 data, but there should be 10793 unique data as each Q,I pair was answered by 3 workers.
	#Uniquify qi_applicable data
	unique_qi_applicable=uniquify_data(qi_applicable)		
		
	print "Extracting Features ... " #use unique_qi_applicable data for extracting features.
	#question_caption_features, applicable_labels= feature_extract_naive()
	question_caption_features, applicable_labels= feature_extract_word2vec(unique_qi_applicable, image_captions)
	#question_features, caption_features, labels = feature_extract_lstm()	
	
	X_train=question_caption_features[0:len(question_caption_features)*2/3]
	y_train=applicable_labels[0:len(question_caption_features)*2/3]

	#X_train_ques=question_features[0:len(question_features)*2/3]
	#X_train_cap=caption_features[0:len(question_features)*2/3]
	
	#y_train= labels[0:len(question_features)*2/3]

	print "Training ..."
	
	loadweights=cfg.loadWeights
	if loadweights!=None:
		model=train_model(X_train,y_train,loadweights)
	else:
		model=train_model(X_train,y_train,loadweights)
		
		if cfg.saveModel:
			print "Trained model saved to file : outputmodels/"+str(datetime.now())+"_"+str(cfg.cap_type)+"_avgw2v.h5"
			model.save_weights('outputmodels/'+str(datetime.now())+"_"+str(cfg.cap_type)+'_avgw2v.h5')
	#model=train_model_lstm(X_train_ques, X_train_cap, y_train)
	


	X_test=question_caption_features[(len(question_caption_features)*2/3)+1:len(question_caption_features)]
	y_test=applicable_labels[(len(question_caption_features)*2/3)+1:len(question_caption_features)]
	
	#X_test_ques=question_features[len(question_features)*2/3+1:len(question_features)]
	#X_test_cap=caption_features[len(question_features)*2/3+1:len(question_features)]
	
	#y_test= labels[len(question_features)*2/3+1:len(question_features)]
	
	
	print "Testing on Train..."
	pred,gt,pred_n,gt_n=test_model(X_train,y_train,model)		
	#pred,gt,pred_n,gt_n=test_model_lstm(X_train_ques, X_train_cap, y_train ,model)

#	print accuracy_score(gt,pred)
	print "Relevant Class Recall: "+str(recall_score(gt,pred))
	print "Relevant Class Precision: "+str(precision_score(gt,pred))

#	print accuracy_score(gt_n,pred_n)
	print "Irrelevant Class Recall: "+str(recall_score(gt_n,pred_n))
	print "Irrelevant Class Precision: "+str(precision_score(gt_n,pred_n))
	print "Normalized Acc: mean(Recall_Relevant_Class, Recall_Irrelevant_Class) : "
	print (recall_score(gt,pred)+recall_score(gt_n,pred_n))/2

	print "Testing on Test..."
	pred,gt,pred_n,gt_n=test_model(X_test,y_test,model)		
	#pred,gt,pred_n,gt_n=test_model_lstm(X_test_ques, X_test_cap, y_test ,model)	
	
#	print accuracy_score(gt,pred)
	print "Relevant Class Recall: "+str(recall_score(gt,pred))
	print "Relevant Class Precision: "+str(precision_score(gt,pred))

#	print accuracy_score(gt_n,pred_n)
	print "Irrelevant Class Recall: "+str(recall_score(gt_n,pred_n))
	print "Irrelevant Class Precision: "+str(precision_score(gt_n,pred_n))
	print "Normalized Acc: mean(Recall_Relevant_Class, Recall_Irrelevant_Class) : "	
	print (recall_score(gt,pred)+recall_score(gt_n,pred_n))/2


def run_naive_model(cfg):	
	tcount=0
	print "Loading Data ..."
	image_captions, qi_applicable, vocab, invertvocab= load_data(args)
	
	#qi_applicable has 32139 data, but there should be 10793 unique data as each Q,I pair was answered by 3 workers.
	#Uniquify qi_applicable data
	unique_qi_applicable=uniquify_data(qi_applicable)		
	
	print "Extracting Features ... " #use unique_qi_applicable data for extracting features.
	question_caption_features, applicable_labels= feature_extract_naive(unique_qi_applicable, image_captions, vocab, invertvocab)
	#question_caption_features, applicable_labels= feature_extract_word2vec()
	#question_features, caption_features, labels = feature_extract_lstm()	
	
	X_train=question_caption_features[0:len(question_caption_features)*2/3]
	y_train=applicable_labels[0:len(question_caption_features)*2/3]

	#X_train_ques=question_features[0:len(question_features)*2/3]
	#X_train_cap=caption_features[0:len(question_features)*2/3]
	
	#y_train= labels[0:len(question_features)*2/3]

	print "Defining Model ..."
	loadweights=cfg.loadWeights
	if loadweights!=None:
		model=train_model_naive(X_train,y_train,vocab, loadweights)
	else:
		model=train_model_naive(X_train,y_train, vocab)
		
		if cfg.saveModel:
			print "Trained model saved to file : outputmodels/"+str(datetime.now())+"_"+str(cfg.cap_type)+"_bow.h5"
			model.save_weights('outputmodels/'+str(datetime.now())+"_"+str(cfg.cap_type)+'_bow.h5')
	#model=train_model_lstm(X_train_ques, X_train_cap, y_train)
	
	X_test=question_caption_features[(len(question_caption_features)*2/3)+1:len(question_caption_features)]
	y_test=applicable_labels[(len(question_caption_features)*2/3)+1:len(question_caption_features)]
	
	#X_test_ques=question_features[len(question_features)*2/3+1:len(question_features)]
	#X_test_cap=caption_features[len(question_features)*2/3+1:len(question_features)]
	
	#y_test= labels[len(question_features)*2/3+1:len(question_features)]
	
	print "Testing on Train..."
	pred,gt,pred_n,gt_n=test_model(X_train,y_train,model)		
	#pred,gt,pred_n,gt_n=test_model_lstm(X_train_ques, X_train_cap, y_train ,model)

#	print accuracy_score(gt,pred)
	print "Relevant Class Recall: "+str(recall_score(gt,pred))
	print "Relevant Class Precision: "+str(precision_score(gt,pred))

#	print accuracy_score(gt_n,pred_n)
	print "Irrelevant Class Recall: "+str(recall_score(gt_n,pred_n))
	print "Irrelevant Class Precision: "+str(precision_score(gt_n,pred_n))
	print "Normalized Acc: mean(Recall_Relevant_Class, Recall_Irrelevant_Class) : "
	print (recall_score(gt,pred)+recall_score(gt_n,pred_n))/2

	print "Testing on Test..."
	pred,gt,pred_n,gt_n=test_model(X_test,y_test,model)		
	#pred,gt,pred_n,gt_n=test_model_lstm(X_test_ques, X_test_cap, y_test ,model)	
	
#	print accuracy_score(gt,pred)
	print "Relevant Class Recall: "+str(recall_score(gt,pred))
	print "Relevant Class Precision: "+str(precision_score(gt,pred))

#	print accuracy_score(gt_n,pred_n)
	print "Irrelevant Class Recall: "+str(recall_score(gt_n,pred_n))
	print "Irrelevant Class Precision: "+str(precision_score(gt_n,pred_n))
	print "Normalized Acc: mean(Recall_Relevant_Class, Recall_Irrelevant_Class) : "	
	print (recall_score(gt,pred)+recall_score(gt_n,pred_n))/2

def run_lstm_model(cfg):	
	tcount=0
	print "Loading Data ..."
	image_captions, qi_applicable, vocab, invertvocab= load_data(args)
	
	#qi_applicable has 32139 data, but there should be 10793 unique data as each Q,I pair was answered by 3 workers.
	#Uniquify qi_applicable data
	unique_qi_applicable=uniquify_data(qi_applicable)		
		
	print "Extracting Features ... " #use unique_qi_applicable data for extracting features.
	#question_caption_features, applicable_labels= feature_extract_naive()
	#question_caption_features, applicable_labels= feature_extract_word2vec()
	question_features, caption_features, labels = feature_extract_lstm(unique_qi_applicable, image_captions)	
	
	#X_train=question_caption_features[0:len(question_caption_features)*2/3]
	#y_train=applicable_labels[0:len(question_caption_features)*2/3]

	X_train_ques=question_features[0:len(question_features)*2/3]
	X_train_cap=caption_features[0:len(question_features)*2/3]
	
	y_train= labels[0:len(question_features)*2/3]

	print "Defining Model ..."
	#model=train_model(X_train,y_train)
	if cfg.loadWeights!=None:
		model=train_model_lstm(X_train_ques, X_train_cap, y_train, cfg.loadWeights)
	else:
		model=train_model_lstm(X_train_ques, X_train_cap, y_train)	
		if cfg.saveModel:
			print "Trained model saved to file : outputmodels/"+str(datetime.now())+"_"+str(cfg.cap_type)+"_lstm.h5"
			model.save_weights('outputmodels/'+str(datetime.now())+"_"+str(cfg.cap_type)+'_lstm.h5')
	#X_test=question_caption_features[(len(question_caption_features)*2/3)+1:len(question_caption_features)]
	#y_test=applicable_labels[(len(question_caption_features)*2/3)+1:len(question_caption_features)]
	
	X_test_ques=question_features[len(question_features)*2/3+1:len(question_features)]
	X_test_cap=caption_features[len(question_features)*2/3+1:len(question_features)]
	
	y_test= labels[len(question_features)*2/3+1:len(question_features)]	
	
	print "Testing on Train..."
	#pred,gt,pred_n,gt_n=test_model(X_train,y_train,model)		
	pred,gt,pred_n,gt_n=test_model_lstm(X_train_ques, X_train_cap, y_train ,model)

#	print accuracy_score(gt,pred)
	print "Relevant Class Recall: "+str(recall_score(gt,pred))
	print "Relevant Class Precision: "+str(precision_score(gt,pred))

#	print accuracy_score(gt_n,pred_n)
	print "Irrelevant Class Recall: "+str(recall_score(gt_n,pred_n))
	print "Irrelevant Class Precision: "+str(precision_score(gt_n,pred_n))
	print "Normalized Acc: mean(Recall_Relevant_Class, Recall_Irrelevant_Class) : "
	print (recall_score(gt,pred)+recall_score(gt_n,pred_n))/2

	print "Testing on Test..."
	#pred,gt,pred_n,gt_n=test_model(X_test,y_test,model)		
	pred,gt,pred_n,gt_n=test_model_lstm(X_test_ques, X_test_cap, y_test ,model)	
	
#	print accuracy_score(gt,pred)
	print "Relevant Class Recall: "+str(recall_score(gt,pred))
	print "Relevant Class Precision: "+str(precision_score(gt,pred))

#	print accuracy_score(gt_n,pred_n)
	print "Irrelevant Class Recall: "+str(recall_score(gt_n,pred_n))
	print "Irrelevant Class Precision: "+str(precision_score(gt_n,pred_n))
	print "Normalized Acc: mean(Recall_Relevant_Class, Recall_Irrelevant_Class) : "	
	print (recall_score(gt,pred)+recall_score(gt_n,pred_n))/2


def parse_args():
	parser= argparse.ArgumentParser(description='Train/Test Question Caption Similarity Models')
	parser.add_argument('--captype', dest='cap_type', help='qc for question-caption similarity, qq for question-question similarity, qdq for question-diverse questions similarity', default='qq', type=str) 
	parser.add_argument('--model', dest='whichModel', help='Options: avgw2v for Avg W2V method, lstm for LSTM on W2V method, or bow for Bag of Words Method as described in paper', default='avgw2v', type=str)
	parser.add_argument('--loadWeights', dest='loadWeights', help='(optional) path to weight file to be loaded', default=None, type=str) #0520highestaccmodel_w2v_avg_quesques.h5 for best avgw2v model
	parser.add_argument('--saveModel', dest='saveModel', help='FALSE to NOT save trained model', default=True, type=bool)
	if len(sys.argv) ==1:
		parser.print_help()
		sys.exit(1)

	args=parser.parse_args()
	return args

global w2v
if __name__=='__main__':

	args=parse_args()
	
	if args.whichModel=='avgw2v':
		print "Loading Word2Vec Dictionary. This may take a long time..."
		from gensim import *
		w2v=models.Word2Vec.load_word2vec_format('w2vmodel/GoogleNews-vectors-negative300.bin', binary=True)
		run_avg_w2v_model(args)
	elif args.whichModel=='lstm':
		print "Loading Word2Vec Google Dictionary. This may take a long time..."
		from gensim import *
		w2v=models.Word2Vec.load_word2vec_format('w2vmodel/GoogleNews-vectors-negative300.bin', binary=True)
		run_lstm_model(args)
	elif args.whichModel=='bow':
		run_naive_model(args)


